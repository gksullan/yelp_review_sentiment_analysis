{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('bmh')\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import pickle\n",
    "import string\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions for preprocessing text \n",
    "\n",
    "def remove_nums(s):\n",
    "    # 1. Replace numbers with strings\n",
    "    s = re.sub(r'\\d+', '', s)\n",
    "    return s\n",
    "    \n",
    "def remove_punct(s):\n",
    "    # 2. Punctuation removal, new line removal\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    s = s.translate(translator)\n",
    "    s = re.sub('\\n', '', s)\n",
    "    return s\n",
    "\n",
    "def remove_nonenglish(s):\n",
    "    #remove non english characters\n",
    "    s = re.sub(r'[^\\x00-\\x7f]',r'', s) \n",
    "    return s\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data to be processed\n",
    "df = pd.read_pickle('data/yelp_review1pct_business_merge.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean, preprocess string in \"text\" column of dataframe\n",
    "df['clean_text'] = df.text.apply(remove_nums).apply(remove_punct).apply(remove_nonenglish).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train-test split before vectorizing text data\n",
    "labels = df.pop('sentiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df, labels, test_size=0.1, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_pickle('data/sentiment_y_train.pkl')\n",
    "y_test.to_pickle('data/sentiment_y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text generator object to generate lemmas on TRAINING dataset\n",
    "textgen_train = ([tok.lemma_ for tok in nlp(text)] for text in x_train.clean_text)\n",
    "\n",
    "#text generator object to generate lemmas on TEST dataset\n",
    "textgen_test = ([tok.lemma_ for tok in nlp(text)] for text in x_test.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_pipe = Pipeline([('tfidf', TfidfVectorizer(tokenizer=list, lowercase=False, min_df=0.01, max_df=0.2)),\n",
    "                     ('svd', TruncatedSVD(n_components=100, random_state=12))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_svd = bow_pipe.fit_transform(textgen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_svd = bow_pipe.transform(textgen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_svd_df = pd.DataFrame(x_train_svd)\n",
    "x_train_svd_df.set_index(x_train.index, inplace=True)\n",
    "x_train_svd_all = x_train_svd_df.join(x_train)\n",
    "\n",
    "x_test_svd_df = pd.DataFrame(x_test_svd)\n",
    "x_test_svd_df.set_index(x_test.index, inplace=True)\n",
    "x_test_svd_all = x_test_svd_df.join(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_svd_all.to_pickle('data/review_1pct_bus_svd_x_train.pkl')\n",
    "x_test_svd_all.to_pickle('data/review_1pct_bus_svd_x_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text generator object to generate lemmas on TRAINING dataset\n",
    "textgen_train = ([tok.lemma_ for tok in nlp(text)] for text in x_train.clean_text)\n",
    "\n",
    "#text generator object to generate lemmas on TEST dataset\n",
    "textgen_test = ([tok.lemma_ for tok in nlp(text)] for text in x_test.clean_text)\n",
    "\n",
    "tfidf_pipe = Pipeline([('tfidf', TfidfVectorizer(tokenizer=list, lowercase=False, min_df=0.01, max_df=0.2))])\n",
    "\n",
    "x_train_bow = tfidf_pipe.fit_transform(textgen_train)\n",
    "x_test_bow = tfidf_pipe.transform(textgen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bow_df = pd.DataFrame(x_train_bow.todense())\n",
    "x_train_bow_df.columns = tfidf_pipe.named_steps['tfidf'].get_feature_names()\n",
    "x_train_bow_df.set_index(x_train.index, inplace=True)\n",
    "x_train_bow_all = x_train_bow_df.join(x_train, lsuffix='_tok')\n",
    "\n",
    "x_test_bow_df = pd.DataFrame(x_test_bow.todense())\n",
    "x_test_bow_df.columns = tfidf_pipe.named_steps['tfidf'].get_feature_names()\n",
    "x_test_bow_df.set_index(x_test.index, inplace=True)\n",
    "x_test_bow_all = x_test_bow_df.join(x_test, lsuffix='_tok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bow_all.to_pickle('data/review_1pct_bus_bow_x_train.pkl')\n",
    "x_test_bow_all.to_pickle('data/review_1pct_bus_bow_x_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using word embeddings\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "        self.dim = 300\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Doc.vector defaults to an average of the token vectors.\n",
    "        # https://spacy.io/api/doc#vector\n",
    "        return [self.nlp(text).vector for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_pipe = Pipeline(steps=[(\"mean_embeddings\", SpacyVectorTransformer(nlp))])\n",
    "\n",
    "x_train_em = embed_pipe.transform(x_train.text)\n",
    "x_test_em = embed_pipe.transform(x_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_em_df = pd.DataFrame(x_train_em)\n",
    "x_train_em_df.set_index(x_train.index, inplace=True)\n",
    "x_train_em_all = x_train_em_df.join(x_train, lsuffix='_tok')\n",
    "\n",
    "x_test_em_df = pd.DataFrame(x_test_em)\n",
    "x_test_em_df.set_index(x_test.index, inplace=True)\n",
    "x_test_em_all = x_test_em_df.join(x_test, lsuffix='_tok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_em_all.to_pickle('data/review_1pct_bus_em_x_train.pkl')\n",
    "x_test_em_all.to_pickle('data/review_1pct_bus_em_x_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
